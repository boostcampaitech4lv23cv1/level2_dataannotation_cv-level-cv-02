{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "import math\n",
    "import json\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import cv2\n",
    "import albumentations as A\n",
    "from torch.utils.data import Dataset\n",
    "from shapely.geometry import Polygon\n",
    "\n",
    "\n",
    "def cal_distance(x1, y1, x2, y2):\n",
    "    '''calculate the Euclidean distance'''\n",
    "    return math.sqrt((x1 - x2)**2 + (y1 - y2)**2)\n",
    "\n",
    "\n",
    "def move_points(vertices, index1, index2, r, coef):\n",
    "    '''move the two points to shrink edge\n",
    "    Input:\n",
    "        vertices: vertices of text region <numpy.ndarray, (8,)>\n",
    "        index1  : offset of point1\n",
    "        index2  : offset of point2\n",
    "        r       : [r1, r2, r3, r4] in paper\n",
    "        coef    : shrink ratio in paper\n",
    "    Output:\n",
    "        vertices: vertices where one edge has been shinked\n",
    "    '''\n",
    "    index1 = index1 % 4\n",
    "    index2 = index2 % 4\n",
    "    x1_index = index1 * 2 + 0\n",
    "    y1_index = index1 * 2 + 1\n",
    "    x2_index = index2 * 2 + 0\n",
    "    y2_index = index2 * 2 + 1\n",
    "\n",
    "    r1 = r[index1]\n",
    "    r2 = r[index2]\n",
    "    length_x = vertices[x1_index] - vertices[x2_index]\n",
    "    length_y = vertices[y1_index] - vertices[y2_index]\n",
    "    length = cal_distance(vertices[x1_index], vertices[y1_index], vertices[x2_index], vertices[y2_index])\n",
    "    if length > 1:\n",
    "        ratio = (r1 * coef) / length\n",
    "        vertices[x1_index] += ratio * (-length_x)\n",
    "        vertices[y1_index] += ratio * (-length_y)\n",
    "        ratio = (r2 * coef) / length\n",
    "        vertices[x2_index] += ratio * length_x\n",
    "        vertices[y2_index] += ratio * length_y\n",
    "    return vertices\n",
    "\n",
    "\n",
    "def shrink_poly(vertices, coef=0.3):\n",
    "    '''shrink the text region\n",
    "    Input:\n",
    "        vertices: vertices of text region <numpy.ndarray, (8,)>\n",
    "        coef    : shrink ratio in paper\n",
    "    Output:\n",
    "        v       : vertices of shrinked text region <numpy.ndarray, (8,)>\n",
    "    '''\n",
    "    x1, y1, x2, y2, x3, y3, x4, y4 = vertices\n",
    "    r1 = min(cal_distance(x1,y1,x2,y2), cal_distance(x1,y1,x4,y4))\n",
    "    r2 = min(cal_distance(x2,y2,x1,y1), cal_distance(x2,y2,x3,y3))\n",
    "    r3 = min(cal_distance(x3,y3,x2,y2), cal_distance(x3,y3,x4,y4))\n",
    "    r4 = min(cal_distance(x4,y4,x1,y1), cal_distance(x4,y4,x3,y3))\n",
    "    r = [r1, r2, r3, r4]\n",
    "\n",
    "    # obtain offset to perform move_points() automatically\n",
    "    if cal_distance(x1,y1,x2,y2) + cal_distance(x3,y3,x4,y4) > \\\n",
    "       cal_distance(x2,y2,x3,y3) + cal_distance(x1,y1,x4,y4):\n",
    "        offset = 0 # two longer edges are (x1y1-x2y2) & (x3y3-x4y4)\n",
    "    else:\n",
    "        offset = 1 # two longer edges are (x2y2-x3y3) & (x4y4-x1y1)\n",
    "\n",
    "    v = vertices.copy()\n",
    "    v = move_points(v, 0 + offset, 1 + offset, r, coef)\n",
    "    v = move_points(v, 2 + offset, 3 + offset, r, coef)\n",
    "    v = move_points(v, 1 + offset, 2 + offset, r, coef)\n",
    "    v = move_points(v, 3 + offset, 4 + offset, r, coef)\n",
    "    return v\n",
    "\n",
    "\n",
    "def get_rotate_mat(theta):\n",
    "    '''positive theta value means rotate clockwise'''\n",
    "    return np.array([[math.cos(theta), -math.sin(theta)], [math.sin(theta), math.cos(theta)]])\n",
    "\n",
    "\n",
    "def rotate_vertices(vertices, theta, anchor=None):\n",
    "    '''rotate vertices around anchor\n",
    "    Input:\n",
    "        vertices: vertices of text region <numpy.ndarray, (8,)>\n",
    "        theta   : angle in radian measure\n",
    "        anchor  : fixed position during rotation\n",
    "    Output:\n",
    "        rotated vertices <numpy.ndarray, (8,)>\n",
    "    '''\n",
    "    v = vertices.reshape((4,2)).T\n",
    "    if anchor is None:\n",
    "        anchor = v[:,:1]\n",
    "    rotate_mat = get_rotate_mat(theta)\n",
    "    res = np.dot(rotate_mat, v - anchor)\n",
    "    return (res + anchor).T.reshape(-1)\n",
    "\n",
    "\n",
    "def get_boundary(vertices):\n",
    "    '''get the tight boundary around given vertices\n",
    "    Input:\n",
    "        vertices: vertices of text region <numpy.ndarray, (8,)>\n",
    "    Output:\n",
    "        the boundary\n",
    "    '''\n",
    "    x1, y1, x2, y2, x3, y3, x4, y4 = vertices\n",
    "    x_min = min(x1, x2, x3, x4)\n",
    "    x_max = max(x1, x2, x3, x4)\n",
    "    y_min = min(y1, y2, y3, y4)\n",
    "    y_max = max(y1, y2, y3, y4)\n",
    "    return x_min, x_max, y_min, y_max\n",
    "\n",
    "\n",
    "def cal_error(vertices):\n",
    "    '''default orientation is x1y1 : left-top, x2y2 : right-top, x3y3 : right-bot, x4y4 : left-bot\n",
    "    calculate the difference between the vertices orientation and default orientation\n",
    "    Input:\n",
    "        vertices: vertices of text region <numpy.ndarray, (8,)>\n",
    "    Output:\n",
    "        err     : difference measure\n",
    "    '''\n",
    "    x_min, x_max, y_min, y_max = get_boundary(vertices)\n",
    "    x1, y1, x2, y2, x3, y3, x4, y4 = vertices\n",
    "    err = cal_distance(x1, y1, x_min, y_min) + cal_distance(x2, y2, x_max, y_min) + \\\n",
    "          cal_distance(x3, y3, x_max, y_max) + cal_distance(x4, y4, x_min, y_max)\n",
    "    return err\n",
    "\n",
    "\n",
    "def find_min_rect_angle(vertices):\n",
    "    '''find the best angle to rotate poly and obtain min rectangle\n",
    "    Input:\n",
    "        vertices: vertices of text region <numpy.ndarray, (8,)>\n",
    "    Output:\n",
    "        the best angle <radian measure>\n",
    "    '''\n",
    "    angle_interval = 1\n",
    "    angle_list = list(range(-90, 90, angle_interval))\n",
    "    area_list = []\n",
    "    for theta in angle_list:\n",
    "        rotated = rotate_vertices(vertices, theta / 180 * math.pi)\n",
    "        x1, y1, x2, y2, x3, y3, x4, y4 = rotated\n",
    "        temp_area = (max(x1, x2, x3, x4) - min(x1, x2, x3, x4)) * \\\n",
    "                    (max(y1, y2, y3, y4) - min(y1, y2, y3, y4))\n",
    "        area_list.append(temp_area)\n",
    "\n",
    "    sorted_area_index = sorted(list(range(len(area_list))), key=lambda k: area_list[k])\n",
    "    min_error = float('inf')\n",
    "    best_index = -1\n",
    "    rank_num = 10\n",
    "    # find the best angle with correct orientation\n",
    "    for index in sorted_area_index[:rank_num]:\n",
    "        rotated = rotate_vertices(vertices, angle_list[index] / 180 * math.pi)\n",
    "        temp_error = cal_error(rotated)\n",
    "        if temp_error < min_error:\n",
    "            min_error = temp_error\n",
    "            best_index = index\n",
    "    return angle_list[best_index] / 180 * math.pi\n",
    "\n",
    "\n",
    "def is_cross_text(start_loc, length, vertices):\n",
    "    '''check if the crop image crosses text regions\n",
    "    Input:\n",
    "        start_loc: left-top position\n",
    "        length   : length of crop image\n",
    "        vertices : vertices of text regions <numpy.ndarray, (n,8)>\n",
    "    Output:\n",
    "        True if crop image crosses text region\n",
    "    '''\n",
    "    if vertices.size == 0:\n",
    "        return False\n",
    "    start_w, start_h = start_loc\n",
    "    a = np.array([start_w, start_h, start_w + length, start_h, start_w + length, start_h + length,\n",
    "                  start_w, start_h + length]).reshape((4, 2))\n",
    "    p1 = Polygon(a).convex_hull\n",
    "    for vertice in vertices:\n",
    "        p2 = Polygon(vertice.reshape((4, 2))).convex_hull\n",
    "        inter = p1.intersection(p2).area\n",
    "        if 0.01 <= inter / p2.area <= 0.99:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def crop_img(img, vertices, labels, length):\n",
    "    '''crop img patches to obtain batch and augment\n",
    "    Input:\n",
    "        img         : PIL Image\n",
    "        vertices    : vertices of text regions <numpy.ndarray, (n,8)>\n",
    "        labels      : 1->valid, 0->ignore, <numpy.ndarray, (n,)>\n",
    "        length      : length of cropped image region\n",
    "    Output:\n",
    "        region      : cropped image region\n",
    "        new_vertices: new vertices in cropped region\n",
    "    '''\n",
    "    h, w = img.height, img.width\n",
    "    # confirm the shortest side of image >= length\n",
    "    if h >= w and w < length:\n",
    "        img = img.resize((length, int(h * length / w)), Image.BILINEAR)\n",
    "    elif h < w and h < length:\n",
    "        img = img.resize((int(w * length / h), length), Image.BILINEAR)\n",
    "    ratio_w = img.width / w\n",
    "    ratio_h = img.height / h\n",
    "    assert(ratio_w >= 1 and ratio_h >= 1)\n",
    "\n",
    "    new_vertices = np.zeros(vertices.shape)\n",
    "    if vertices.size > 0:\n",
    "        new_vertices[:,[0,2,4,6]] = vertices[:,[0,2,4,6]] * ratio_w\n",
    "        new_vertices[:,[1,3,5,7]] = vertices[:,[1,3,5,7]] * ratio_h\n",
    "\n",
    "    # find random position\n",
    "    remain_h = img.height - length\n",
    "    remain_w = img.width - length\n",
    "    flag = True\n",
    "    cnt = 0\n",
    "    while flag and cnt < 1000:\n",
    "        cnt += 1\n",
    "        start_w = int(np.random.rand() * remain_w)\n",
    "        start_h = int(np.random.rand() * remain_h)\n",
    "        flag = is_cross_text([start_w, start_h], length, new_vertices[labels==1,:])\n",
    "    box = (start_w, start_h, start_w + length, start_h + length)\n",
    "    region = img.crop(box)\n",
    "    if new_vertices.size == 0:\n",
    "        return region, new_vertices\n",
    "\n",
    "    new_vertices[:,[0,2,4,6]] -= start_w\n",
    "    new_vertices[:,[1,3,5,7]] -= start_h\n",
    "    return region, new_vertices\n",
    "\n",
    "\n",
    "def rotate_all_pixels(rotate_mat, anchor_x, anchor_y, length):\n",
    "    '''get rotated locations of all pixels for next stages\n",
    "    Input:\n",
    "        rotate_mat: rotatation matrix\n",
    "        anchor_x  : fixed x position\n",
    "        anchor_y  : fixed y position\n",
    "        length    : length of image\n",
    "    Output:\n",
    "        rotated_x : rotated x positions <numpy.ndarray, (length,length)>\n",
    "        rotated_y : rotated y positions <numpy.ndarray, (length,length)>\n",
    "    '''\n",
    "    x = np.arange(length)\n",
    "    y = np.arange(length)\n",
    "    x, y = np.meshgrid(x, y)\n",
    "    x_lin = x.reshape((1, x.size))\n",
    "    y_lin = y.reshape((1, x.size))\n",
    "    coord_mat = np.concatenate((x_lin, y_lin), 0)\n",
    "    rotated_coord = np.dot(rotate_mat, coord_mat - np.array([[anchor_x], [anchor_y]])) + \\\n",
    "                                                   np.array([[anchor_x], [anchor_y]])\n",
    "    rotated_x = rotated_coord[0, :].reshape(x.shape)\n",
    "    rotated_y = rotated_coord[1, :].reshape(y.shape)\n",
    "    return rotated_x, rotated_y\n",
    "\n",
    "\n",
    "def resize_img(img, vertices, size):\n",
    "    h, w = img.height, img.width\n",
    "    ratio = size / max(h, w)\n",
    "    if w > h:\n",
    "        img = img.resize((size, int(h * ratio)), Image.BILINEAR)\n",
    "    else:\n",
    "        img = img.resize((int(w * ratio), size), Image.BILINEAR)\n",
    "    new_vertices = vertices * ratio\n",
    "    return img, new_vertices\n",
    "\n",
    "\n",
    "def adjust_height(img, vertices, ratio=0.2):\n",
    "    '''adjust height of image to aug data\n",
    "    Input:\n",
    "        img         : PIL Image\n",
    "        vertices    : vertices of text regions <numpy.ndarray, (n,8)>\n",
    "        ratio       : height changes in [0.8, 1.2]\n",
    "    Output:\n",
    "        img         : adjusted PIL Image\n",
    "        new_vertices: adjusted vertices\n",
    "    '''\n",
    "    ratio_h = 1 + ratio * (np.random.rand() * 2 - 1)\n",
    "    old_h = img.height\n",
    "    new_h = int(np.around(old_h * ratio_h))\n",
    "    img = img.resize((img.width, new_h), Image.BILINEAR)\n",
    "\n",
    "    new_vertices = vertices.copy()\n",
    "    if vertices.size > 0:\n",
    "        new_vertices[:,[1,3,5,7]] = vertices[:,[1,3,5,7]] * (new_h / old_h)\n",
    "    return img, new_vertices\n",
    "\n",
    "\n",
    "def rotate_img(img, vertices, angle_range=10):\n",
    "    '''rotate image [-10, 10] degree to aug data\n",
    "    Input:\n",
    "        img         : PIL Image\n",
    "        vertices    : vertices of text regions <numpy.ndarray, (n,8)>\n",
    "        angle_range : rotate range\n",
    "    Output:\n",
    "        img         : rotated PIL Image\n",
    "        new_vertices: rotated vertices\n",
    "    '''\n",
    "    center_x = (img.width - 1) / 2\n",
    "    center_y = (img.height - 1) / 2\n",
    "    angle = angle_range * (np.random.rand() * 2 - 1)\n",
    "    img = img.rotate(angle, Image.BILINEAR)\n",
    "    new_vertices = np.zeros(vertices.shape)\n",
    "    for i, vertice in enumerate(vertices):\n",
    "        new_vertices[i,:] = rotate_vertices(vertice, -angle / 180 * math.pi, np.array([[center_x],[center_y]]))\n",
    "    return img, new_vertices\n",
    "\n",
    "\n",
    "def generate_roi_mask(image, vertices, labels):\n",
    "    mask = np.ones(image.shape[:2], dtype=np.float32)\n",
    "    ignored_polys = []\n",
    "    for vertice, label in zip(vertices, labels):\n",
    "        if label == 0:\n",
    "            ignored_polys.append(np.around(vertice.reshape((4, 2))).astype(np.int32))\n",
    "    cv2.fillPoly(mask, ignored_polys, 0)\n",
    "    return mask\n",
    "\n",
    "\n",
    "def filter_vertices(vertices, labels, ignore_under=0, drop_under=0):\n",
    "    if drop_under == 0 and ignore_under == 0:\n",
    "        return vertices, labels\n",
    "\n",
    "    new_vertices, new_labels = vertices.copy(), labels.copy()\n",
    "\n",
    "    areas = np.array([Polygon(v.reshape((4, 2))).convex_hull.area for v in vertices])\n",
    "    labels[areas < ignore_under] = 0\n",
    "\n",
    "    if drop_under > 0:\n",
    "        passed = areas >= drop_under\n",
    "        new_vertices, new_labels = new_vertices[passed], new_labels[passed]\n",
    "\n",
    "    return new_vertices, new_labels\n",
    "\n",
    "\n",
    "class SceneTextDataset(Dataset):\n",
    "    def __init__(self, root_dir, split='train', image_size=1024, crop_size=512, color_jitter=True,\n",
    "                 normalize=True):\n",
    "        with open(osp.join(root_dir, 'ufo/random_split/{}.json'.format(split)), 'r') as f:\n",
    "            anno = json.load(f)\n",
    "\n",
    "        self.anno = anno\n",
    "        self.image_fnames = sorted(anno['images'].keys())\n",
    "        self.image_dir = osp.join(root_dir, 'images')\n",
    "\n",
    "        self.image_size, self.crop_size = image_size, crop_size\n",
    "        self.color_jitter, self.normalize = color_jitter, normalize\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_fnames)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_fname = self.image_fnames[idx]\n",
    "        image_fpath = osp.join(self.image_dir, image_fname)\n",
    "\n",
    "        vertices, labels = [], []\n",
    "        for word_info in self.anno['images'][image_fname]['words'].values():\n",
    "\n",
    "            points = np.array(word_info['points']).flatten()\n",
    "\n",
    "            # 8개넘어가면 안되게끔, polygon에 외접한 직사각형으로 수정!\n",
    "            if len(points) > 8 : \n",
    "                x = [round(points[i]) for i in range(len(points)) if i%2 ==0]\n",
    "                y = [round(points[i]) for i in range(len(points)) if i%2 !=0]\n",
    "                tmp_points = np.array([[x_pos, y_pos] for x_pos, y_pos in zip(x,y)])\n",
    "                rect = cv2.minAreaRect(tmp_points)\n",
    "                circum_box= cv2.boxPoints(rect)\n",
    "                points = np.array(circum_box).flatten()\n",
    "\n",
    "            vertices.append(points)\n",
    "            labels.append(int(not word_info['illegibility']))\n",
    "\n",
    "        vertices, labels = np.array(vertices, dtype=np.float32), np.array(labels, dtype=np.int64)\n",
    "\n",
    "        vertices, labels = filter_vertices(vertices, labels, ignore_under=10, drop_under=1)\n",
    "\n",
    "        image = Image.open(image_fpath)\n",
    "        image, vertices = resize_img(image, vertices, self.image_size)\n",
    "        image, vertices = adjust_height(image, vertices)\n",
    "        image, vertices = rotate_img(image, vertices)\n",
    "        image, vertices = crop_img(image, vertices, labels, self.crop_size)\n",
    "\n",
    "        if image.mode != 'RGB':\n",
    "            image = image.convert('RGB')\n",
    "            \n",
    "        image = np.array(image)\n",
    "\n",
    "        funcs = []\n",
    "        if self.color_jitter:\n",
    "            funcs.append(A.ColorJitter(0.5, 0.5, 0.5, 0.25))\n",
    "        if self.normalize:\n",
    "            funcs.append(A.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5)))\n",
    "        transform = A.Compose(funcs)\n",
    "\n",
    "        image = transform(image=image)['image']\n",
    "        word_bboxes = np.reshape(vertices, (-1, 4, 2))\n",
    "        roi_mask = generate_roi_mask(image, vertices, labels)\n",
    "\n",
    "        return image, word_bboxes, roi_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '/opt/ml/input/data/ICDAR17_Korean'\n",
    "data = SceneTextDataset(DATA_PATH, split='train', image_size=1024, crop_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[263.97005561 567.66910775]\n",
      "  [393.97142668 581.30662354]\n",
      "  [392.03189439 602.48047976]\n",
      "  [261.10245844 593.14510065]]\n",
      "\n",
      " [[235.12257598 529.6177032 ]\n",
      "  [331.65810989 537.92561223]\n",
      "  [321.34235536 567.47153596]\n",
      "  [232.4874564  559.75937428]]\n",
      "\n",
      " [[453.77826451 419.45216193]\n",
      "  [465.15165197 422.24805754]\n",
      "  [464.45640112 435.04336995]\n",
      "  [453.08295044 432.24750005]]\n",
      "\n",
      " [[271.84535458 366.51947209]\n",
      "  [478.63199325 386.38625864]\n",
      "  [462.77444185 510.36808824]\n",
      "  [192.09518468 486.63893375]]\n",
      "\n",
      " [[336.97545148 538.33805108]\n",
      "  [426.56902665 548.02119788]\n",
      "  [424.14499676 579.2728491 ]\n",
      "  [335.14224204 569.63546799]]\n",
      "\n",
      " [[244.15564918 294.38433492]\n",
      "  [455.07799562 314.57193766]\n",
      "  [452.31671185 350.17161296]\n",
      "  [241.31005194 331.07101624]]]\n",
      "***************\n",
      "[[263.97005561 567.66910775]\n",
      " [393.97142668 581.30662354]\n",
      " [392.03189439 602.48047976]\n",
      " [261.10245844 593.14510065]]\n",
      "\n",
      "[[235.12257598 529.6177032 ]\n",
      " [331.65810989 537.92561223]\n",
      " [321.34235536 567.47153596]\n",
      " [232.4874564  559.75937428]]\n",
      "\n",
      "[[453.77826451 419.45216193]\n",
      " [465.15165197 422.24805754]\n",
      " [464.45640112 435.04336995]\n",
      " [453.08295044 432.24750005]]\n",
      "\n",
      "[[271.84535458 366.51947209]\n",
      " [478.63199325 386.38625864]\n",
      " [462.77444185 510.36808824]\n",
      " [192.09518468 486.63893375]]\n",
      "\n",
      "[[336.97545148 538.33805108]\n",
      " [426.56902665 548.02119788]\n",
      " [424.14499676 579.2728491 ]\n",
      " [335.14224204 569.63546799]]\n",
      "\n",
      "[[244.15564918 294.38433492]\n",
      " [455.07799562 314.57193766]\n",
      " [452.31671185 350.17161296]\n",
      " [241.31005194 331.07101624]]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7751/461714906.py:264: DeprecationWarning: BILINEAR is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BILINEAR instead.\n",
      "  img = img.resize((int(w * ratio), size), Image.BILINEAR)\n",
      "/tmp/ipykernel_7751/461714906.py:282: DeprecationWarning: BILINEAR is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BILINEAR instead.\n",
      "  img = img.resize((img.width, new_h), Image.BILINEAR)\n",
      "/tmp/ipykernel_7751/461714906.py:303: DeprecationWarning: BILINEAR is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BILINEAR instead.\n",
      "  img = img.rotate(angle, Image.BILINEAR)\n"
     ]
    }
   ],
   "source": [
    "data0 = data[50]\n",
    "data_0_1 = data0[1]\n",
    "\n",
    "print(data_0_1)\n",
    "print('***************')\n",
    "\n",
    "for i in data_0_1:\n",
    "    print(i)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
